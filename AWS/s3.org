#+Title:S3 Como Usar
#+Subtitle:

* o que sao os buckets
  https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html


* criar um bucket
    
   #+NAME:aws s3api create-bucket --bucket my-bucket --region us-east-1
   #+BEGIN_SRC shell :session s1 :results output :exports both
      aws s3api create-bucket --bucket wagner --region us-east-1
   #+END_SRC

   #+RESULTS: aws s3api create-bucket --bucket my-bucket --region us-east-1
   : An error occurred (BucketAlreadyExists) when calling the CreateBucket operation: The requested bucket name is not available. The bucket namespace is shared by all users of the system. Please select a different name and try again.


   se for usar outra regiao, fora da us-east-1 sera necessario usar
   sempre  a opcao LocationConstraint

   
   #+NAME: aws s3api create-bucket --bucket my-bucket --region eu-west-1 --create-bucket-configuration LocationConstraint=eu-west-1
   #+BEGIN_SRC shell :session s1 :results output :exports both
       aws s3api create-bucket --bucket meuS3Bucket --region eu-west-1 --create-bucket-configuration LocationConstraint=eu-west-1
   #+END_SRC


* listar buckets
  
   #+NAME: aws s3api list-buckets --query "Buckets[].Name"
   #+BEGIN_SRC shell :session s1 :results output :exports both
      aws s3api list-buckets --query "Buckets[].Name"
   #+END_SRC

   #+RESULTS: aws s3api list-buckets --query "Buckets[].Name"
   : [
   :     "br.com.fzlbpms",
   :     "br.usp.sin5009",
   :     "ipgg-curso-geronto",
   :     "www.planosdeaulas.com.br"
   : ]
   
   
   #+NAME:aws s3 ls (1)
   #+BEGIN_SRC shell :session s1 :results output :exports both
      echo "[s3 ls]"
      aws s3 ls
      echo "[s3 ls www.planosdeaulas.com.br]"
      aws s3 ls www.planosdeaulas.com.br
   #+END_SRC

   #+RESULTS: aws s3 ls (1)
   : 2019-10-13 18:06:58 br.com.fzlbpms
   : 2019-10-29 14:02:05 br.usp.sin5009
   : 2020-01-19 21:48:17 ipgg-curso-geronto
   : 2020-04-04 17:20:33 www.planosdeaulas.com.br


   
   #+NAME:                     
   #+BEGIN_SRC shell :session s1 :results output :exports both
      
   #+END_SRC


* ls pra visualizar conteudo dos buckets   
  
   #+NAME:aws s3 ls s3://br.usp.sin5009
   #+BEGIN_SRC shell :session s1 :results output :exports both      
      #aws s3 ls s3://tgsbucket --recursive
      aws s3 ls s3://br.usp.sin5009 --recursive  --human-readable --summarize
   #+END_SRC

   #+RESULTS: aws s3 ls s3://br.usp.sin5009
   : 
   : 2019-10-29 15:04:01    0 Bytes trabalho/
   : 2019-11-28 14:04:46    3.8 KiB trabalho/startprocess.html
   : 
   : Total Objects: 2
   :    Total Size: 3.8 KiB


* fazer upload de um arquivo
  
   #+NAME: aws s3 sync s3://tgsbucket/backup $DirComOsPlanosDeAulas
   #+BEGIN_SRC shell :session s1 :results output :exports both
   DirComOsPlanosDeAulas=/home/wagner/envs/env-dev/sources/somewritings/var/publishing-directory/planosdeaulas
   bucketName=www.planosdeaulas.com.br
   echo "aws s3 sync s3://$bucketName $DirComOsPlanosDeAulas"
   aws s3 sync s3://$bucketName $DirComOsPlanosDeAulas
   #+END_SRC

   #+RESULTS: aws s3 sync s3://tgsbucket/backup $DirComOsPlanosDeAulas
   : 
   : [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ aws s3 sync s3://www.planosdeaulas.com.br /home/wagner/envs/env-dev/sources/somewritings/var/publishing-directory/planosdeaulas


* fazer upload multipart de arquivo(s)
  https://docs.aws.amazon.com/cli/latest/reference/s3api/create-multipart-upload.html
  https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html
  
  Qdo vc vai fazer um upload de um arquivo grande, faz muito sentido
  fazer um multipart upload, ou seja, fazer o upload em partes e
  obviamente poder gerenciar essas partes.

  Um upload multi parte e um feito em tres partes: 
  1) Vc inicializa um upload
     O importante aqui e que vc recebe um id do upload que vc iniciou
     e vc vai usar esse id pra qualquer necessidade posterior
     referente a esse upload
  2) Vc comeca o upload
     Vc pode fazer upload de partes especificas do seu arquivo, de 1 a
     10000. Cada parte uploadada a aws retorna uma Etag header na
     resposta. Vc tem que salvar essa etag de cada parte porque
     vc vai precisar delas pra finalizar o upload.
  3) Vc termina o upload (qdo terminar o upload, e claro)
     
  E possivle listar uploads multi parte em progresso, obter uma
  listagem das partes
  
  
** criando um upload multipart  
   Esse comando comeca um upload multipart de arquivo e retorna um id
   que pode ser utilizado depois pra continuar ou para parar o upload
   
   
   #+NAME:                     
   #+BEGIN_SRC shell :session s1 :results output :exports both
      
   #+END_SRC
  
  
   #+NAME:                     
   #+BEGIN_SRC shell :session s1 :results output :exports both
   aws s3 cp myvideo.mp4 s3://mybucket/
   #+END_SRC


* sites estaticos com s3
  https://docs.aws.amazon.com/AmazonS3/latest/user-guide/access-points.html
  https://docs.aws.amazon.com/AmazonS3/latest/dev/creating-access-points.html#access-points-vpc


* criar folder em um bucket
  

* mais exemplos
 
   #+NAME:mais exemplos
   #+BEGIN_SRC shell :session s1 :results output :exports both
   DirComOsPlanosDeAulas=/home/wagner/envs/env-dev/sources/somewritings/var/publishing-directory/planosdeaulas
   bucketName=www.planosdeaulas.com.br
   export AwsAccountId=...
   #revisar as permissoes do buckets antes de usar os comandos

   #echo "s3 ls s3://$bucketName"
   #aws s3 ls s3://$bucketName
   #echo "aws s3 ls s3://$bucketName --recursive  --human-readable --summarize"
   #aws s3 ls s3://$bucketName --recursive  --human-readable --summarize
   #echo "aws s3 website s3://tgsbucket/ --index-document index.html --error-document error.html"
   
   
   #echo "aws s3control create-access-point --name wwwplanosdeaulas --account-id $AwsAccountId --bucket $$bucketName --region us-east-1"
   #aws s3 website s3://$bucketName --index-document index.html --error-document erro.html
   #aws s3control create-access-point --name wwwplanosdeaulas --account-id $AwsAccountId --bucket $$bucketName --region us-east-1
   

   #aws iam list-users
   #+END_SRC

   #+RESULTS: mais exemplos
   : 
   : [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ aws s3control create-access-point --name wwwplanosdeaulas --account-id AKIAQ5IQ2LQ46IV2TBGC --bucket 27174bucketName --region us-east-1
   : [36m[[m[34mwagner@Unknown[m [32mAWS[m[36m][m $ 
   : An error occurred (AccessDenied) when calling the CreateAccessPoint operation: Access Denied


* refs
  https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-vpcs.html
  https://docs.aws.amazon.com/cli/latest/reference/s3api/
  https://docs.aws.amazon.com/pt_br/AmazonS3/latest/dev/UsingObjects.html
  https://s3.console.aws.amazon.com/s3/spotlight?region=us-east-1
  https://www.thegeekstuff.com/2019/04/aws-s3-cli-examples/
  https://aws.amazon.com/pt/storagegateway/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc
  https://docs.aws.amazon.com/cli/latest/reference/s3api/create-multipart-upload.html
  https://docs.aws.amazon.com/cli/latest/reference/s3api/list-multipart-uploads.html
  https://docs.aws.amazon.com/cli/latest/reference/s3api/upload-part.html
  https://docs.aws.amazon.com/cli/latest/reference/s3api/upload-part-copy.html
  https://docs.aws.amazon.com/cli/latest/reference/s3api/complete-multipart-upload.html
